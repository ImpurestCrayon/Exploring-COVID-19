{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Variables and map to Folder\n",
    "import_path = 'C:/Users/ianmc/OneDrive/Documents/Work/Data/news_blogs_coronavirus'\n",
    "os.chdir(import_path)\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format('JSON'))]\n",
    "print(all_filenames)\n",
    "\n",
    "#Read in file(s)\n",
    "json_data = pd.concat((pd.read_json(f,orient='columns', lines=True) for f in all_filenames), ignore_index=True)\n",
    "#json_data = pd.read_json(all_filenames[0], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unsused Columns to run faster\n",
    "#unused_columns = ['organizations', 'uuid', 'author', 'url', 'ord_in_thread','title', 'locations', 'entities',\n",
    "                  'highlightText', 'language','persons', 'text', 'external_links', 'crawled','highlightTitle']\n",
    "#json_data.drop(unused_columns, axis=1)\n",
    "\n",
    "#change date columns to show just date\n",
    "json_data['published'] = pd.to_datetime(json_data['published']).dt.date\n",
    "json_data['crawled'] = pd.to_datetime(json_data['crawled']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a first round of text cleaning techniques\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)\n",
    "\n",
    "clean_json_data = pd.DataFrame(json_data.text.apply(round1))\n",
    "\n",
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)\n",
    "\n",
    "clean_json_data = pd.DataFrame(clean_json_data.text.apply(round2))\n",
    "\n",
    "#add clean text data to orignal file\n",
    "json_data.insert(column='clean_text', loc=0, value=clean_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More code to come this is just the cleaning part so far -Ian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = 'C:/Users/ianmc/OneDrive/Documents/Work/Data/news_blogs_coronavirus/'\n",
    "us_count_per_day.to_csv((export_path), index = True, header = True, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}